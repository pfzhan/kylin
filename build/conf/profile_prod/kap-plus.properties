

# set the this to true to enable kap columnar storage before running kylin.sh
kap.storage.columnar.start-own-spark=true

# columnar engine definition
kylin.storage.provider.100=io.kyligence.kap.storage.parquet.ParquetStorage
kylin.engine.provider.100=io.kyligence.kap.engine.mr.KapMRBatchCubingEngine
kylin.storage.provider.99=io.kyligence.kap.storage.parquet.ParquetSpliceStorage
kylin.engine.provider.99=io.kyligence.kap.engine.mr.KapSpliceMRBatchCubingEngine
kylin.storage.default=100
kylin.engine.default=100

## use snappy for prod env
kap.storage.columnar.page-compression=SNAPPY
kap.storage.columnar.ii-spill-threshold-mb=512

# spark configuration

## for any spark config entry in http://spark.apache.org/docs/latest/configuration.html#environment-variables, prefix it with "kap.storage.columnar.env" and append here
### path to hadoop conf, must be local on the server running kylin.sh. it is sth like /etc/hadoop/conf
kap.storage.columnar.spark-env.HADOOP_CONF_DIR=${kylin_hadoop_conf_dir}

## for any spark config entry in http://spark.apache.org/docs/latest/configuration.html#spark-properties, prefix it with "kap.storage.columnar.spark-conf" and append here
kap.storage.columnar.spark-conf.spark.driver.extraJavaOptions=-Dhdp.version=current -Dsun.io.serialization.extendedDebugInfo=true -Dlog4j.configuration=file:${LOG4J_DIR}/spark-driver-log4j.properties -Dkylin.home=${KYLIN_HOME} -Dkap.spark.identifier=${KAP_SPARK_IDENTIFIER}
kap.storage.columnar.spark-conf.spark.executor.extraJavaOptions=-Dhdp.version=current -Dlog4j.configuration=spark-executor-log4j.properties -Dlog4j.debug -Dkap.spark.identifier=${KAP_SPARK_IDENTIFIER} -Dkap.hdfs.working.dir=${KAP_HDFS_WORKING_DIR} -Dkap.metadata.url=${KAP_METADATA_URL}
kap.storage.columnar.spark-conf.spark.executor.extraClassPath=${KAP_HDFS_APPENDER_JAR}
kap.storage.columnar.spark-conf.spark.yarn.am.extraJavaOptions=-Dhdp.version=current
kap.storage.columnar.spark-conf.spark.driver.memory=8192m
kap.storage.columnar.spark-conf.spark.executor.memory=8192m
kap.storage.columnar.spark-conf.yarn.am.memory=8192m
kap.storage.columnar.spark-conf.spark.executor.cores=5
kap.storage.columnar.spark-conf.spark.executor.instances=4
kap.storage.columnar.spark-conf.spark.task.maxFailures=1
kap.storage.columnar.spark-conf.spark.ui.port=4041
kap.storage.columnar.spark-conf.spark.locality.wait=0s

# realization providers
kylin.metadata.realization-providers=org.apache.kylin.cube.CubeManager,org.apache.kylin.storage.hybrid.HybridManager,io.kyligence.kap.cube.raw.RawTableManager

