## Copyright (C) 2016 Kyligence Inc. All rights reserved.
##
## http://kyligence.io
##
## This software is the confidential and proprietary information of
## Kyligence Inc. ("Confidential Information"). You shall not disclose
## such Confidential Information and shall use it only in accordance
## with the terms of the license agreement you entered into with
## Kyligence Inc.
##
## THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
## "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
## LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
## A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
## OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
## SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
## LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
## DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
## THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
## (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
## OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

# KAP provides two configuration profiles: minimal and production(by default).
# To switch to production:
# cd $KYLIN_HOME/conf
# ln -sfn profile_prod profile
# To switch to minimal(for sandbox test):
# ln -sfn profile_min profile



# minimal profile is same as prod, except for some conservative resource allocation behaviors
 
### METADATA | ENV ###

# Env DEV|QA|PROD
kylin.env=PROD

### SERVICE ###
# List of web servers in use, this enables one web server instance to sync up with other servers.
#kylin.server.cluster-servers=localhost:7070

### SOURCE ###


### STORAGE ###

# The metadata store in jdbc
kylin.metadata.url=

# Working folder in HDFS, make sure user has the right access to the hdfs directory
kylin.env.hdfs-working-dir=hdfs://sandbox/kylin

### JOB ###

# max job retry on error, default 0: no retry
kylin.job.retry=0

# If true, job engine will not assume that hadoop CLI reside on the same server as it self
# you will have to specify kylin.job.remote-cli-hostname, kylin.job.remote-cli-username and kylin.job.remote-cli-password
# It should not be set to "true" unless you're NOT running Kylin.sh on a hadoop client machine
# (Thus kylin instance has to ssh to another real hadoop client machine to execute hive,hadoop commands)
kylin.job.use-remote-cli=false

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-hostname=sandbox

kylin.job.remote-cli-port=22

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-username=root

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-password=hadoop

# Used by test cases to prepare synthetic data for sample cube
kylin.job.remote-cli-working-dir=/tmp/kylin

# Max count of concurrent jobs running
kylin.job.max-concurrent-jobs=10

# Time interval to check hadoop job status
kylin.engine.mr.yarn-check-interval-seconds=10

# for test
kylin.engine.mr.uhc-reducer-count=3

### CUBE ###


### QUERY ###
kylin.query.pushdown.runner-class-name=io.kyligence.kap.query.pushdown.PushDownRunnerSparkImpl

### SECURITY ###

# Spring security profile, options: testing, ldap, saml
# with "testing" profile, user can use pre-defined name/pwd like KYLIN/ADMIN to login
kylin.security.profile=testing

# Default roles and admin roles in LDAP, for ldap and saml
kylin.security.acl.default-role=ROLE_ANALYST,ROLE_MODELER
kylin.security.acl.admin-role=ROLE_ADMIN

# LDAP authentication configuration
kylin.security.ldap.connection-server=ldap://ldap_server:389
kylin.security.ldap.connection-username=
kylin.security.ldap.connection-password=

# LDAP user account directory;
kylin.security.ldap.user-search-base=
kylin.security.ldap.user-search-pattern=
kylin.security.ldap.user-group-search-base=

# LDAP service account directory
kylin.security.ldap.service-search-base=
kylin.security.ldap.service-search-pattern=
kylin.security.ldap.service-group-search-base=

# SAML configurations for SSO
# SAML IDP metadata file location
kylin.security.saml.metadata-file=classpath:sso_metadata.xml
kylin.security.saml.metadata-entity-base-url=https://hostname/kylin
kylin.security.saml.context-scheme=https
kylin.security.saml.context-server-name=hostname
kylin.security.saml.context-server-port=443
kylin.security.saml.context-path=/kylin

### MAIL ###
# If true, will send email notification;
#kylin.job.notification-enabled=true
#kylin.job.notification-mail-enable-starttls=true
#kylin.job.notification-mail-host=smtp.office365.com
#kylin.job.notification-mail-port=587
#kylin.job.notification-mail-username=kylin@example.com
#kylin.job.notification-mail-password=mypassword
#kylin.job.notification-mail-sender=kylin@example.com


### OTHER ###

# for tests
kylin.test.bcc.new.key=some-value
kylin.engine.mr.config-override.test1=test1
kylin.engine.mr.config-override.test2=test2
kylin.job.lock=org.apache.kylin.job.lock.MockJobLock


# this file will be appended to kylin.properties, used by io.kyligence.kap.common.util.TempMetadataBuilder
kylin.server.init-tasks=
kylin.source.provider.11=io.kyligence.kap.engine.spark.source.NSparkDataSource
kylin.source.provider.9=io.kyligence.kap.engine.spark.source.NSparkDataSource


kap.storage.columnar.shard-size-mb=256
kap.storage.columnar.shard-min=1
kap.storage.columnar.shard-max=1000
kap.storage.columnar.spark-conf.spark.port.maxRetries=128

### Spark conf overwrite for cube engine
kylin.engine.spark-conf.spark.yarn.submit.file.replication=1
kylin.engine.spark-conf.spark.master=yarn
#kylin.engine.spark-conf.spark.submit.deployMode=cluster
kylin.engine.spark-conf.spark.yarn.executor.memoryOverhead=384
kylin.engine.spark-conf.spark.yarn.driver.memoryOverhead=256
kylin.engine.spark-conf.spark.executor.memory=1000M
kylin.engine.spark-conf.spark.executor.cores=2
kylin.engine.spark-conf.spark.executor.instances=1
kylin.engine.spark-conf.spark.storage.memoryFraction=0.3
kylin.engine.spark-conf.spark.eventLog.enabled=true
kylin.engine.spark-conf.spark.port.maxRetries=128
kylin.engine.spark-conf.spark.history.fs.logDirectory=hdfs\:///spark-history
kylin.engine.spark-conf.spark.eventLog.dir=hdfs\:///spark-history
kylin.engine.spark-conf.spark.driver.extraJavaOptions=-Dhdp.version=current
kylin.engine.spark-conf.spark.yarn.am.extraJavaOptions=-Dhdp.version=current
kylin.engine.spark-conf.spark.executor.extraJavaOptions=-Dhdp.version=current -Dlog4j.configuration=spark-executor-log4j.properties -Dlog4j.debug -Dkap.hdfs.working.dir=${kylin.env.hdfs-working-dir} -Dkap.metadata.url=${kylin.metadata.url} -Dkap.spark.category=job -Dkap.spark.identifier=${job.id} -Dkap.spark.jobName=${job.stepId}
kylin.engine.spark-conf.spark.yarn.dist.files=${KYLIN_HOME}/conf/spark-executor-log4j.properties
kylin.engine.spark.job-jar=../lib/newten-job.jar
kap.storage.columnar.ii-spill-threshold-mb=128


# TODO: implement ACL
kylin.query.interceptors=

kylin.metadata.store-factory=io.kyligence.kap.common.persistence.KapMetaStoreFactory
