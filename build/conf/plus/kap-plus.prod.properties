

# set the this to true to enable kap columnar storage before running kylin.sh
kap.storage.columnar.enabled=true

# columnar engine definition
kylin.storage.provider.100=io.kyligence.kap.storage.parquet.ParquetStorage
kylin.engine.provider.100=io.kyligence.kap.engine.mr.KapMRBatchCubingEngine
kylin.storage.default=100
kylin.engine.default=100
## use snappy for prod env
kap.storage.columnar.page-compression=SNAPPY

# spark configuration

## for any spark config entry in http://spark.apache.org/docs/latest/configuration.html#environment-variables, prefix it with "kap.storage.columnar.env" and append here
### path to hadoop conf, must be local on the server running kylin.sh. it is sth like /etc/hadoop/conf
kap.storage.columnar.spark-env.HADOOP_CONF_DIR=/etc/hadoop/conf

## for any spark config entry in http://spark.apache.org/docs/latest/configuration.html#spark-properties, prefix it with "kap.storage.columnar.conf" and append here
kap.storage.columnar.spark-conf.spark.driver.extraJavaOptions=-Dhdp.version=current -Dsun.io.serialization.extendedDebugInfo=true
kap.storage.columnar.spark-conf.spark.yarn.am.extraJavaOptions=-Dhdp.version=current
kap.storage.columnar.spark-conf.spark.driver.memory=8192m
kap.storage.columnar.spark-conf.spark.executor.memory=8192m
kap.storage.columnar.spark-conf.spark.executor.cores=5
kap.storage.columnar.spark-conf.spark.executor.instances=4

# realization providers
kylin.metadata.realization-providers=org.apache.kylin.cube.CubeManager,org.apache.kylin.storage.hybrid.HybridManager,io.kyligence.kap.cube.raw.RawTableManager

