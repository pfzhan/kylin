# Kyligence Inc. License

# raw index
kylin.cube.measure.customMeasureType.indexedraw=io.kyligence.kap.measure.indexedraw.IndexedRawMeasureTypeFactory

# set the this to true to enable kap columnar storage before running kylin.sh
kap.storage.columnar.enabled=true

# columnar engine definition
kylin.storage.engine.100=io.kyligence.kap.storage.parquet.ParquetStorage
kylin.cube.engine.100=io.kyligence.kap.engine.mr.KapMRBatchCubingEngine
kylin.default.storage.engine=100
kylin.default.cube.engine=100

# spark configuration

## path to hadoop conf, must be local on the server running kylin.sh. it is sth like /etc/hadoop/conf
kap.storage.columnar.env.HADOOP_CONF_DIR=/etc/hadoop/conf

## for any spark config entry in http://spark.apache.org/docs/1.6.2/configuration.html, prefix it with "kap.storage.columnar.conf" and append here
kap.storage.columnar.conf.spark.driver.extraJavaOptions=-Dhdp.version=current -Dsun.io.serialization.extendedDebugInfo=true
kap.storage.columnar.conf.spark.yarn.am.extraJavaOptions=-Dhdp.version=current

# realization providers
kylin.realization.providers=org.apache.kylin.cube.CubeManager,org.apache.kylin.storage.hybrid.HybridManager,io.kyligence.kap.cube.raw.RawTableManager

#
kap.storage.columnar.conf.spark.driver.memory=512m
kap.storage.columnar.conf.spark.executor.memory=512m
kap.storage.columnar.conf.spark.yarn.am.memory=512m
kap.storage.columnar.conf.spark.executor.cores=1
kap.storage.columnar.conf.spark.executor.instances=1
