#
# Copyright (C) 2016 Kyligence Inc. All rights reserved.
#
# http://kyligence.io
#
# This software is the confidential and proprietary information of
# Kyligence Inc. ("Confidential Information"). You shall not disclose
# such Confidential Information and shall use it only in accordance
# with the terms of the license agreement you entered into with
# Kyligence Inc.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#

# Env DEV|QA|PROD
kylin.env=UT


### SERVICE ###

# Optional information for the owner of kylin platform, it can be your team's email
# Currently it will be attached to each kylin's htable attribute
kylin.storage.hbase.owner-tag=whoami@kylin.apache.org

# List of web servers in use, this enables one web server instance to sync up with other servers.
#kylin.server.cluster-servers=localhost:7070

### SOURCE ###


### STORAGE ###

# The metadata store in hbase
kylin.metadata.url=

# The storage for final cube file in hbase
kylin.storage.url=hbase

# Working folder in HDFS, make sure user has the right access to the hdfs directory
kylin.env.hdfs-working-dir=/kylin

# Compression codec for htable, valid value [none, snappy, lzo, gzip, lz4]
kylin.storage.hbase.compression-codec=snappy

### JOB ###

# max job retry on error, default 0: no retry
kylin.job.retry=0

# If true, job engine will not assume that hadoop CLI reside on the same server as it self
# you will have to specify kylin.job.remote-cli-hostname, kylin.job.remote-cli-username and kylin.job.remote-cli-password
# It should not be set to "true" unless you're NOT running Kylin.sh on a hadoop client machine 
# (Thus kylin instance has to ssh to another real hadoop client machine to execute hbase,hive,hadoop commands)
kylin.job.use-remote-cli=false

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-hostname=

kylin.job.remote-cli-port=22

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-username=

# Only necessary when kylin.job.use-remote-cli=true
kylin.job.remote-cli-password=

# Used by test cases to prepare synthetic data for sample cube
kylin.job.remote-cli-working-dir=/tmp/kylin

# Max count of concurrent jobs running
kylin.job.max-concurrent-jobs=10

# Time interval to check hadoop job status
kylin.engine.mr.yarn-check-interval-seconds=10

# for test
kylin.engine.mr.uhc-reducer-count=3

### CUBE ###


### QUERY ###


### SECURITY ###

# Spring security profile, options: testing, ldap, saml
# with "testing" profile, user can use pre-defined name/pwd like KYLIN/ADMIN to login
kylin.security.profile=testing

# Default roles and admin roles in LDAP, for ldap and saml
kylin.security.acl.default-role=ROLE_ANALYST,ROLE_MODELER
kylin.security.acl.admin-role=ROLE_ADMIN

# LDAP authentication configuration
kylin.security.ldap.connection-server=ldap://ldap_server:389
kylin.security.ldap.connection-username=
kylin.security.ldap.connection-password=

# LDAP user account directory;
kylin.security.ldap.user-search-base=
kylin.security.ldap.user-search-pattern=
kylin.security.ldap.user-group-search-base=

# LDAP service account directory
kylin.security.ldap.service-search-base=
kylin.security.ldap.service-search-pattern=
kylin.security.ldap.service-group-search-base=

# SAML configurations for SSO
# SAML IDP metadata file location
kylin.security.saml.metadata-file=classpath:sso_metadata.xml
kylin.security.saml.metadata-entity-base-url=https://hostname/kylin
kylin.security.saml.context-scheme=https
kylin.security.saml.context-server-name=hostname
kylin.security.saml.context-server-port=443
kylin.security.saml.context-path=/kylin

### MAIL ###
# If true, will send email notification;
#kylin.job.notification-enabled=true
#kylin.job.notification-mail-enable-starttls=true
#kylin.job.notification-mail-host=smtp.office365.com
#kylin.job.notification-mail-port=587
#kylin.job.notification-mail-username=kylin@example.com
#kylin.job.notification-mail-password=mypassword
#kylin.job.notification-mail-sender=kylin@example.com


### OTHER ###

# for tests
kylin.test.bcc.new.key=some-value
kylin.engine.mr.config-override.test1=test1
kylin.engine.mr.config-override.test2=test2
kylin.job.lock=org.apache.kylin.job.lock.MockJobLockDup
kylin.job.lock=org.apache.kylin.job.lock.MockJobLock




# this file will be appended to kylin.properties, used by io.kyligence.kap.common.util.TempMetadataBuilder
kylin.server.init-tasks=
kylin.source.provider.11=io.kyligence.kap.engine.spark.mockup.CsvSource
kylin.source.provider.9=io.kyligence.kap.engine.spark.source.NSparkDataSource

kylin.metadata.hbasemapping-adapter=io.kyligence.kap.cube.hbasemapping.HBaseMappingAdapter

kap.storage.columnar.shard-size-mb=256
kap.storage.columnar.shard-min=1
kap.storage.columnar.shard-max=1000

### Spark conf overwrite for cube engine
kylin.engine.spark-conf.spark.yarn.submit.file.replication=1
kylin.engine.spark-conf.spark.master=yarn
#kylin.engine.spark-conf.spark.submit.deployMode=cluster
kylin.engine.spark-conf.spark.yarn.executor.memoryOverhead=384
kylin.engine.spark-conf.spark.yarn.driver.memoryOverhead=256
kylin.engine.spark-conf.spark.executor.memory=2000M
kylin.engine.spark-conf.spark.executor.cores=4
kylin.engine.spark-conf.spark.executor.instances=1
kylin.engine.spark-conf.spark.storage.memoryFraction=0.3
kylin.engine.spark-conf.spark.eventLog.enabled=true
kylin.engine.spark-conf.spark.history.fs.logDirectory=hdfs\:///spark-history
kylin.engine.spark-conf.spark.eventLog.dir=hdfs\:///spark-history
kylin.engine.spark-conf.spark.yarn.jar=hdfs://sandbox.hortonworks.com:8020/kylin/spark/spark-assembly-1.6.3-hadoop2.6.0.jar
kylin.engine.spark-conf.spark.driver.extraJavaOptions=-Dhdp.version=current
kylin.engine.spark-conf.spark.yarn.am.extraJavaOptions=-Dhdp.version=current
kylin.engine.spark-conf.spark.executor.extraJavaOptions=-Dhdp.version=current
kylin.engine.spark-conf.spark.sql.adaptive.enabled=true

# TODO: implement ACL
kylin.query.interceptors=

kylin.favorite.storage-url=kylin_favorite@jdbc,url=jdbc:mysql://sandbox:3306/kylin,username=root,password=

kylin.metadata.first-day-of-week=monday

kylin.metadata.distributed-lock-impl=org.apache.kylin.job.lock.MockedDistributedLock$MockedFactory

kylin.metadata.store-factory=io.kyligence.kap.common.persistence.KapMetaStoreFactory


kap.metric.diagnosis.influxDB-address=sandbox:8086
#kylin.engine.spark.build-class-name=io.kyligence.kap.engine.spark.job.MockedDFBuildJob
