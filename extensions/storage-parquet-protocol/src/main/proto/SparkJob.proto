//
// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//

option java_package = "io.kyligence.kap.storage.parquet.cube.spark.rpc.generated";

option java_outer_classname = "SparkJobProtos";

option java_generic_services = true;

option java_generate_equals_and_hash = true;

option optimize_for = SPEED;


//either provided a payload to start new request,
//or streaming fetch next part of result by providing fetchNextKey
message SparkJobRequest { 
    optional SparkJobRequestPayload payload = 1;
    optional string streamIdentifier = 2;
}

message SparkJobRequestPayload {
    required bytes gtScanRequest = 1;
    required string kylinProperties = 2;
    required string realizationType = 3;
    required string realizationId = 4;
    required string segmentId = 5;
    required string dataFolderName = 6;
    required int32 maxRecordLength = 7;
    repeated int32 parquetColumns = 8;
    required bool useII = 9;
    required string queryId = 10;
    required bool spillEnabled = 11 [default = true];
    required int64 maxScanBytes = 12; // must be positive
    required int64 startTime = 13;
    required int32 storageType = 14; // -1 if realizationType is not cube
    required string gtScanRequestId = 15;
}

message SparkJobResponse {
    repeated PartitionResponse partitionResponse = 1;
    required string sparkInstanceIdentifier = 2;
    required string streamIdentifier = 3;

    message PartitionResponse {
        required bytes blob = 1;
        required int64 scannedRows = 2;
        required int64 scannedBytes = 3;
        required int64 returnedRows = 4;
        required string hostname = 5;
        required int64 startLatency = 6;
        required int64 totalDuration = 7;
    }
}

message SparkConfRequest {
    required string name = 1;
}

message SparkConfResponse {
    required string value = 1;
}

message PushDownRequest {
    required string sql = 1;
}

message Row {
    repeated Cell cell = 1;

    message Cell {
        optional string value = 1;
    }
}

message StructField {
    required string name = 1;
    required int32 dataType = 2;
    required string dataTypeName = 3;
    optional int32 precision = 4;
    optional int32 scale = 5;
    optional string table = 6;
    required bool nullable = 7;
}

message PushDownResponse {
    repeated StructField columns = 1;
    repeated Row rows = 2;
}

service JobService {
    rpc submitJob (stream SparkJobRequest) returns (stream SparkJobResponse);
    rpc doPushDownQuery (PushDownRequest) returns (PushDownResponse);
}

service ConfService {
    rpc getConf (SparkConfRequest) returns (SparkConfResponse);
}
