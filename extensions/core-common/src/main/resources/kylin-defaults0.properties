## Copyright (C) 2016 Kyligence Inc. All rights reserved.
##
## http://kyligence.io
##
## This software is the confidential and proprietary information of
## Kyligence Inc. ("Confidential Information"). You shall not disclose
## such Confidential Information and shall use it only in accordance
## with the terms of the license agreement you entered into with
## Kyligence Inc.
##
## THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
## "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
## LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
## A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
## OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
## SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
## LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
## DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
## THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
## (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
## OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

### METADATA | ENV ###

# The metadata store in hbase
kylin.metadata.url=kylin_default_instance@hbase

# Working folder in HDFS, better be qualified absolute path, make sure user has the right permission to this directory
kylin.env.hdfs-working-dir=/kylin

# DEV|QA|PROD. DEV will turn on some dev features, QA and PROD has no difference in terms of functions.
kylin.env=PROD

# The enhanced data model
kylin.metadata.data-model-impl=io.kyligence.kap.metadata.model.KapModel

### SERVER | WEB ###

# Kylin server mode, valid value [all, query, job]
kylin.server.mode=all

# List of web servers in use, this enables one web server instance to sync up with other servers.
# since service discovery is by default enabled in KAP, we don't need it any more
kylin.server.cluster-servers=

# Display timezone on UI,format like[GMT+N or GMT-N]
kylin.web.timezone=GMT+8

kylin.web.cross-domain-enabled=true

### SOURCE ###

# Hive client, valid value [cli, beeline]
kylin.source.hive.client=cli

# Parameters for beeline client, only necessary if hive client is beeline
#kylin.source.hive.beeline-params=-n root --hiveconf hive.security.authorization.sqlstd.confwhitelist.append='mapreduce.job.*|dfs.*' -u jdbc:hive2://localhost:10000

kylin.source.hive.keep-flat-table=false

# Hive database name for putting the intermediate flat tables
kylin.source.hive.database-for-flat-table=default

# Whether redistribute the intermediate flat table before building
kylin.source.hive.redistribute-flat-table=true

### STORAGE ###

# The storage for final cube file in hbase
kylin.storage.url=hbase

# Compression codec for htable, valid value [none, snappy, lzo, gzip, lz4]
kylin.storage.hbase.compression-codec=snappy

# HBase Cluster FileSystem, which serving hbase, format as hdfs://hbase-cluster:8020
# Leave empty if hbase running on same cluster with hive and mapreduce
#kylin.storage.hbase.cluster-fs=

# The cut size for hbase region, in GB.
kylin.storage.hbase.region-cut-gb=5

# The hfile size of GB, smaller hfile leading to the converting hfile MR has more reducers and be faster.
# Set 0 to disable this optimization.
kylin.storage.hbase.hfile-size-gb=2

kylin.storage.hbase.min-region-count=1
kylin.storage.hbase.max-region-count=500

# Optional information for the owner of kylin platform, it can be your team's email
# Currently it will be attached to each kylin's htable attribute
kylin.storage.hbase.owner-tag=whoami@kylin.apache.org

kylin.storage.hbase.coprocessor-mem-gb=3

# The default coprocessor timeout is (hbase.rpc.timeout * 0.9) / 1000 seconds,
# You can set it to a smaller value. 0 means use default.
# kylin.storage.hbase.coprocessor-timeout-seconds=0

### JOB ###

# max job retry on error, default 0: no retry
kylin.job.retry=0

# Max count of concurrent jobs running
kylin.job.max-concurrent-jobs=20

# The percentage of the sampling, default 100%
kylin.job.sampling-percentage=100

# If true, will send email notification;
#kylin.job.notification-enabled=true
#kylin.job.notification-mail-enable-starttls=true
#kylin.job.notification-mail-host=smtp.office365.com
#kylin.job.notification-mail-port=587
#kylin.job.notification-mail-username=kylin@example.com
#kylin.job.notification-mail-password=mypassword
#kylin.job.notification-mail-sender=kylin@example.com

### ENGINE ###

# Time interval to check hadoop job status
kylin.engine.mr.yarn-check-interval-seconds=10

kylin.engine.mr.reduce-input-mb=500

kylin.engine.mr.max-reducer-number=500

kylin.engine.mr.mapper-input-rows=1000000

kylin.engine.mr.config-override.yarn.timeline-service.enabled=false

### CUBE | DICTIONARY ###

kylin.cube.cuboid-scheduler=io.kyligence.kap.cube.cuboid.KapCuboidScheduler

# 'auto', 'inmem', 'layer' or 'random' for testing
kylin.cube.algorithm=layer

# A smaller threshold prefers layer, a larger threshold prefers in-mem
kylin.cube.algorithm.layer-or-inmem-threshold=7

kylin.cube.aggrgroup.max-combination=4096

# differ form Apache Kylin because KAP does not have compatibility issues like kylin. so this option can be true
kylin.cube.aggrgroup.is-mandatory-only-valid=true

kylin.dictionary.max.cardinality=5000000

kylin.snapshot.max-mb=300

### QUERY ###

kylin.query.scan-threshold=10000000

# TABLE/COLUMN/ROW ACL
kylin.query.security.table-acl-enabled=true
kap.query.security.column-acl-enabled=true
kap.query.security.row-acl-enabled=true

kylin.query.interceptors=org.apache.kylin.rest.security.TableInterceptor,io.kyligence.kap.rest.security.ColumnInterceptor

# 3G
kylin.storage.partition.max-scan-bytes=3221225472

# Enable/disable ACL check for cube query
kylin.query.security-enabled=true

kylin.query.cache-enabled=true

kap.query.implicit-computed-column-convert=true

kap.query.jdbc-escape-enabled=true

kap.query.cognos-parentheses-escape=false

kylin.query.access-controller=io.kyligence.kap.query.KapQueryAdvisor
kylin.query.transformers=io.kyligence.kap.query.util.ConvertToComputedColumn,io.kyligence.kap.query.util.EscapeTransformer,org.apache.kylin.query.util.DefaultQueryTransformer,org.apache.kylin.query.util.KeywordDefaultDirtyHack,io.kyligence.kap.query.security.RowFilter,io.kyligence.kap.query.security.HackSelectStarWithColumnACL

kylin.query.realization-filter=io.kyligence.kap.cube.mp.RealizationFilter

kylin.query.force-limit=-1
kylin.query.disable-cube-noagg-sql=false

### SECURITY ###

# Spring security profile, options: testing, ldap, saml
# with "testing" profile, user can use pre-defined name/pwd like KYLIN/ADMIN to login
kylin.security.profile=testing

# Default roles and admin roles in LDAP, for ldap and saml
kylin.security.acl.default-role=ROLE_ANALYST,ROLE_MODELER
kylin.security.acl.admin-role=ROLE_ADMIN

# LDAP authentication configuration
kylin.security.ldap.connection-server=ldap://ldap_server:389
kylin.security.ldap.connection-username=
kylin.security.ldap.connection-password=

# LDAP user account directory;
kylin.security.ldap.user-search-base=
kylin.security.ldap.user-search-pattern=
kylin.security.ldap.user-group-search-base=

# LDAP service account directory
kylin.security.ldap.service-search-base=
kylin.security.ldap.service-search-pattern=
kylin.security.ldap.service-group-search-base=

## LDAP filter ##
# used for searching all users
kylin.security.ldap.user-search-filter=(objectClass=person)
# used for searching all groups
kylin.security.ldap.group-search-filter=(|(objectClass=groupOfNames)(objectClass=group))
# used for searching all users in specific group
kylin.security.ldap.group-member-search-filter=(&(cn={0})(objectClass=groupOfNames))

## SAML configurations for SSO
# SAML IDP metadata file location
kylin.security.saml.metadata-file=classpath:sso_metadata.xml
kylin.security.saml.metadata-entity-base-url=https://hostname/kylin
kylin.security.saml.context-scheme=https
kylin.security.saml.context-server-name=hostname
kylin.security.saml.context-server-port=443
kylin.security.saml.context-path=/kylin

#### PROPERTIES FOR KAP ####





### KAP SERVER | WEB ###

# KAP init
kylin.server.init-tasks=org.apache.kylin.rest.init.ClientInfoTask,io.kyligence.kybot.agent.runner.AgentRunner

# Property Kybot Agent (io.kyligence.kybot.agent.runner.AgentRunner) 
kybot.client.path=kybot

# KAP web UI customization
kap.web.hide-feature.raw-measure=true
kap.web.hide-feature.extendedcolumn-measure=true
kap.web.hide-feature.limited-lookup = true

### METADATA | ENV ###

# the implementation class for jdbc metastore
kylin.metadata.resource-store-provider.jdbc=io.kyligence.kap.common.persistence.JDBCResourceStore



### KAP Job ###

kylin.job.scheduler.provider.100=io.kyligence.kap.job.impl.curator.CuratorScheduler
kylin.job.scheduler.default=100


### KAP Query ###

kylin.query.udf.massin=io.kyligence.kap.query.udf.MassInUDF
kylin.query.derived-filter-translation-threshold=100

### KAP calcite rules ###
kylin.query.calcite.add-rule=io.kyligence.kap.query.optrule.ExtensionOlapJoinRule#INSTANCE
kylin.query.calcite.remove-rule=org.apache.kylin.query.optrule.OLAPJoinRule#INSTANCE


#==========KAP PLUS ONLY START==========

# it's okay if config in this section duplicates with the above section


### METADATA | ENV ###

# realization providers
kylin.metadata.realization-providers=org.apache.kylin.cube.CubeManager,org.apache.kylin.storage.hybrid.HybridManager,io.kyligence.kap.cube.raw.RawTableManager

# hbasemapping adapter
kylin.metadata.hbasemapping-adapter=io.kyligence.kap.cube.hbasemapping.HBaseMappingAdapter

### STORAGE ###

# set the this to true to enable kap columnar storage before running kylin.sh
kap.storage.columnar.start-own-spark=true

# columnar storage definition
kylin.storage.provider.100=io.kyligence.kap.storage.parquet.ParquetStorage
kylin.storage.provider.99=io.kyligence.kap.storage.parquet.ParquetSpliceStorage
kylin.storage.default=99


### ENGINE ###

# columnar engine definition
kylin.engine.provider.98=io.kyligence.kap.engine.spark.KapSparkCubingEngine
kylin.engine.provider.100=io.kyligence.kap.engine.mr.KapMRBatchCubingEngine
kylin.engine.default=100

## use snappy for prod env
kap.storage.columnar.page-compression=SNAPPY
kap.storage.columnar.ii-spill-threshold-mb=512


### SPARK CONFIGURATION ###

# for any spark config entry in http://spark.apache.org/docs/latest/configuration.html#environment-variables, prefix it with "kap.storage.columnar.env" and append here

### path to hadoop conf, must be local on the server running kylin.sh. the value is set to be ${kylin_hadoop_conf_dir}, whose value will be set during bootstrap scripts.
### In most cases, the value can be auto-detected with possible value like /etc/hadoop/conf, so that normal users do not need to worry about this config.
kap.storage.columnar.spark-env.HADOOP_CONF_DIR=${kylin_hadoop_conf_dir}

# for any spark config entry in http://spark.apache.org/docs/latest/configuration.html#spark-properties, prefix it with "kap.storage.columnar.spark-conf" and append here

kap.storage.columnar.spark-conf.spark.executor.extraJavaOptions=-Dhdp.version=current -Dzipkin.collector-hostname=${ZIPKIN_HOSTNAME} -Dzipkin.collector-port=${ZIPKIN_SCRIBE_PORT} -DinfluxDB.address=${INFLUXDB_ADDRESS} -Dlog4j.configuration=spark-executor-log4j.properties -Dlog4j.debug -Dkap.spark.identifier=${KAP_SPARK_IDENTIFIER} -Dkap.hdfs.working.dir=${KAP_HDFS_WORKING_DIR} -Dkap.metadata.url=${KAP_METADATA_URL} -XX:MaxDirectMemorySize=896M
kap.storage.columnar.spark-conf.spark.yarn.am.extraJavaOptions=-Dhdp.version=current
#kap.storage.columnar.spark-conf.spark.serializer=org.apache.spark.serializer.JavaSerializer
kap.storage.columnar.spark-conf.spark.driver.memory=4096m
kap.storage.columnar.spark-conf.spark.executor.memory=4096m
kap.storage.columnar.spark-conf.spark.yarn.executor.memoryOverhead=1024
kap.storage.columnar.spark-conf.yarn.am.memory=1024m
kap.storage.columnar.spark-conf.spark.executor.cores=5
kap.storage.columnar.spark-conf.spark.executor.instances=4
kap.storage.columnar.spark-conf.spark.task.maxFailures=1
kap.storage.columnar.spark-conf.spark.ui.port=4041
kap.storage.columnar.spark-conf.spark.locality.wait=0s
kap.storage.columnar.spark-conf.spark.sql.dialect=hiveql
kap.storage.columnar.spark-conf.spark.hadoop.yarn.timeline-service.enabled=false
kap.storage.columnar.spark-conf.hive.execution.engine=MR


### QUERY ENGINE ###

#kylin.query.pushdown.runner-class-name=io.kyligence.kap.storage.parquet.adhoc.PushDownRunnerSparkImpl
#kylin.query.pushdown.update-enabled=false
kylin.query.pushdown.converter-class-names=io.kyligence.kap.query.util.RestoreFromComputedColumn,io.kyligence.kap.query.util.SparkSQLFunctionConverter,org.apache.kylin.source.adhocquery.HivePushDownConverter
kylin.query.schema-factory=io.kyligence.kap.query.schema.KapSchemaFactory
kap.query.engine.sparder-enabled=false

#==========KAP PLUS ONLY END==========
